{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1reoi3L2YN7KldHDikm7nir8Kdgu5lAY7",
      "authorship_tag": "ABX9TyNya+IWVc4umLRdoMoNbaYk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leomensah/lung-cancer-classification/blob/main/TRANSFER_LEARNING_WITH_RESNET_ENCODER_FOR_LUNG_CANCER_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yd_ztfK2xZdF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import tifffile as tiff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torchvision.transforms.functional as tf\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
        "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
        "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
        "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
        "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
        "}\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "def conv1x1(in_planes, out_planes, stride=1):\n",
        "    \"\"\"1x1 convolution\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride, bias=False)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = conv1x1(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes, stride)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv1x1(planes, planes * self.expansion)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNetEncoder(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000):\n",
        "        super(ResNetEncoder, self).__init__()\n",
        "        self.inplanes = 64\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer0 = nn.Sequential(self.conv1, self.bn1, self.relu)\n",
        "        self.layer1 = nn.Sequential(self.maxpool, self._make_layer(block, 64, layers[0]))\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.out_dim = 512 * block.expansion\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer0(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "def resnet18(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-18 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']), strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet34(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-34 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']), strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet50(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-50 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']), strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet101(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-101 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']), strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "def resnet152(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNetEncoder(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']), strict=False)\n",
        "    return model"
      ],
      "metadata": {
        "id": "61TKmWW7qa06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvLayer(nn.Module):\n",
        "    def __init__(self, num_inputs, num_filters, bn=True, kernel_size=3, stride=1,\n",
        "                 padding=None, transpose=False, dilation=1):\n",
        "        super(ConvLayer, self).__init__()\n",
        "        if padding is None:\n",
        "            padding = (kernel_size-1)//2 if transpose is not None else 0\n",
        "        if transpose:\n",
        "            self.layer = nn.ConvTranspose2d(num_inputs, num_filters, kernel_size=kernel_size,\n",
        "                                            stride=stride, padding=padding, dilation=dilation)\n",
        "        else:\n",
        "            self.layer = nn.Conv2d(num_inputs, num_filters, kernel_size=kernel_size,\n",
        "                                   stride=stride, padding=padding)\n",
        "        nn.init.kaiming_uniform_(self.layer.weight, a=np.sqrt(5))\n",
        "        self.bn_layer = nn.BatchNorm2d(num_filters) if bn else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        out = F.relu(out)\n",
        "        return out if self.bn_layer is None else self.bn_layer(out)\n",
        "    \n",
        "class ConcatLayer(nn.Module):\n",
        "    def forward(self, x, dim=1):\n",
        "        return torch.cat(list(x.values()), dim=dim)\n",
        "    \n",
        "class LambdaLayer(nn.Module):\n",
        "    def __init__(self, f):\n",
        "        super(LambdaLayer, self).__init__()\n",
        "        self.f = f\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.f(x)\n",
        "\n",
        "def upconv2x2(inplanes, outplanes, size=None, stride=1):\n",
        "    if size is not None:\n",
        "        return [\n",
        "            ConvLayer(inplanes, outplanes, kernel_size=2, dilation=2, stride=stride),\n",
        "            nn.Upsample(size=size, mode='bilinear', align_corners=True)\n",
        "        ] \n",
        "    else:\n",
        "        return [\n",
        "            ConvLayer(inplanes, outplanes, kernel_size=2, dilation=2, stride=stride),\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        ]"
      ],
      "metadata": {
        "id": "krcV6c_x7VBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderConnect(nn.Module):\n",
        "    def __init__(self, inplanes, output_size):\n",
        "        super(DecoderConnect, self).__init__()\n",
        "        self.bottom_process = nn.Sequential(\n",
        "            ConvLayer(inplanes, inplanes * 2, kernel_size=3),\n",
        "            ConvLayer(inplanes * 2, inplanes * 2, kernel_size=3),\n",
        "            *upconv2x2(inplanes * 2, inplanes, size=output_size)\n",
        "        )\n",
        "        self.concat_process = nn.Sequential(\n",
        "            ConcatLayer(),\n",
        "            ConvLayer(inplanes * 2, inplanes * 2, kernel_size=1),\n",
        "            ConvLayer(inplanes * 2, inplanes, kernel_size=3),\n",
        "            ConvLayer(inplanes, inplanes, kernel_size=3)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        decoder_input = self.bottom_process(x)\n",
        "        return self.concat_process({0: x, 1: decoder_input})"
      ],
      "metadata": {
        "id": "9WyneX0Rp985"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DynamicUNet(nn.Module):\n",
        "    def __init__(self, encoder, input_size=(224, 224), num_output_channels=None, verbose=0):\n",
        "        super(DynamicUNet, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.verbose = verbose\n",
        "        self.input_size = input_size\n",
        "        self.num_input_channels = 3  # This must be 3 because we're using a ResNet encoder\n",
        "        self.num_output_channels = num_output_channels\n",
        "        \n",
        "        self.decoder = self.setup_decoder()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        encoder_outputs = []\n",
        "        def encoder_output_hook(self, input, output):\n",
        "            encoder_outputs.append(output)\n",
        "\n",
        "        handles = [\n",
        "            child.register_forward_hook(encoder_output_hook) for name, child in self.encoder.named_children()\n",
        "            if name.startswith('layer')\n",
        "        ]\n",
        "\n",
        "        try:\n",
        "            self.encoder(x)\n",
        "        finally:\n",
        "            if self.verbose >= 1:\n",
        "                print(\"Removing all forward handles\")\n",
        "            for handle in handles:\n",
        "                handle.remove()\n",
        "\n",
        "        prev_output = None\n",
        "        for reo, rdl in zip(reversed(encoder_outputs), self.decoder):\n",
        "            if prev_output is not None:\n",
        "                prev_output = rdl({0: reo, 1: prev_output})\n",
        "            else:\n",
        "                prev_output = rdl(reo)\n",
        "        return prev_output\n",
        "                \n",
        "    def setup_decoder(self):\n",
        "        input_sizes = []\n",
        "        output_sizes = []\n",
        "        def shape_hook(self, input, output):\n",
        "            input_sizes.append(input[0].shape)\n",
        "            output_sizes.append(output.shape)\n",
        "\n",
        "        handles = [\n",
        "            child.register_forward_hook(shape_hook) for name, child in self.encoder.named_children()\n",
        "            if name.startswith('layer')\n",
        "        ]    \n",
        "\n",
        "        self.encoder.eval()\n",
        "        test_input = torch.randn(1, self.num_input_channels, *self.input_size)\n",
        "        try:\n",
        "            self.encoder(test_input)\n",
        "        finally:\n",
        "            if self.verbose >= 1:\n",
        "                print(\"Removing all shape hook handles\")\n",
        "            for handle in handles:\n",
        "                handle.remove()\n",
        "        decoder = self.construct_decoder(input_sizes, output_sizes, num_output_channels=self.num_output_channels)\n",
        "        return decoder\n",
        "        \n",
        "    def construct_decoder(self, input_sizes, output_sizes, num_output_channels=None):\n",
        "        decoder_layers = []\n",
        "        for layer_index, (input_size, output_size) in enumerate(zip(input_sizes, output_sizes)):\n",
        "            upsampling_size_factor = int(input_size[-1] / output_size[-1])\n",
        "            upsampling_channel_factor = input_size[-3] / output_size[-3]\n",
        "            next_layer = []\n",
        "            bs, c, h, w = input_size\n",
        "            ops = []\n",
        "            if layer_index == len(input_sizes) - 1:\n",
        "                last_layer_ops = DecoderConnect(output_size[-3], output_size[2:])\n",
        "                last_layer_ops_input = torch.randn(*output_size)\n",
        "                last_layer_concat_ops_output = last_layer_ops(last_layer_ops_input)\n",
        "                next_layer.extend([last_layer_ops])\n",
        "                if upsampling_size_factor > 1 or upsampling_channel_factor != 1:\n",
        "                    last_layer_concat_upconv_op = upconv2x2(output_size[-3], input_size[-3], size=input_size[2:])\n",
        "                    last_layer_concat_upconv_op_output = nn.Sequential(*last_layer_concat_upconv_op)(\n",
        "                        last_layer_concat_ops_output\n",
        "                    )\n",
        "                    next_layer.extend(last_layer_concat_upconv_op)\n",
        "            elif layer_index == 0:\n",
        "                first_layer_concat_ops = [\n",
        "                    ConcatLayer(),\n",
        "                    ConvLayer(output_size[-3] * 2, output_size[-3] * 2, kernel_size=1),\n",
        "                    *upconv2x2(\n",
        "                        output_size[-3] * 2,\n",
        "                        output_size[-3],\n",
        "                        size=[dim * upsampling_size_factor for dim in output_size[2:]]\n",
        "                    ),\n",
        "                    ConvLayer(output_size[-3], output_size[-3], kernel_size=3),\n",
        "                    ConvLayer(\n",
        "                        output_size[-3],\n",
        "                        input_size[-3] if self.num_output_channels is None else self.num_output_channels,\n",
        "                        kernel_size=1\n",
        "                    ),\n",
        "                ]\n",
        "                first_layer_concat_ops_output = nn.Sequential(*first_layer_concat_ops)(\n",
        "                    {0: torch.randn(*output_size), 1: torch.randn(*output_size)}\n",
        "                )\n",
        "                next_layer.extend(first_layer_concat_ops)\n",
        "            else:\n",
        "                middle_layer_concat_ops = [\n",
        "                    ConcatLayer(),\n",
        "                    ConvLayer(output_size[-3] * 2, output_size[-3] * 2, kernel_size=1),\n",
        "                    ConvLayer(output_size[-3] * 2, output_size[-3], kernel_size=3),\n",
        "                    ConvLayer(output_size[-3], output_size[-3], kernel_size=3)\n",
        "                ]\n",
        "                middle_layer_concat_ops_output = nn.Sequential(*middle_layer_concat_ops)(\n",
        "                    {0: torch.randn(*output_size), 1: torch.randn(*output_size)}\n",
        "                )\n",
        "                next_layer.extend(middle_layer_concat_ops)\n",
        "                if upsampling_size_factor > 1 or upsampling_channel_factor != 1:\n",
        "                    middle_layer_concat_upconv_op = upconv2x2(output_size[-3], input_size[-3], size=input_size[2:])\n",
        "                    middle_layer_concat_upconv_op_output = nn.Sequential(*middle_layer_concat_upconv_op)(\n",
        "                        middle_layer_concat_ops_output\n",
        "                    )\n",
        "                    next_layer.extend(middle_layer_concat_upconv_op)\n",
        "            decoder_layers.append(nn.Sequential(*next_layer))\n",
        "        return nn.ModuleList(reversed(decoder_layers))"
      ],
      "metadata": {
        "id": "Vrz5sdhqtPhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RrbOaVk7gjk",
        "outputId": "ff106042-603f-4372-a1b7-f726c35d80db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 33.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.10.0.2)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=0c505645e8dac9c7bd0132094d6a7722091bc83d6dae80f0de350dea7d57a3e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import glob\n",
        "import torch\n",
        "from torch.utils.data.dataset import Dataset\n",
        "import torchvision.transforms.functional as TF\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "class MyLidcDataset(Dataset):\n",
        "  def __init__(self, images_paths, mask_paths):\n",
        "    self.image_paths = images_paths\n",
        "    self.mask_paths = mask_paths\n",
        "\n",
        "    self.albu_transformations =  albu.Compose([\n",
        "            albu.ElasticTransform(alpha=1.1,alpha_affine=0.5,sigma=5,p=0.15),\n",
        "            albu.HorizontalFlip(p=0.15),\n",
        "            ToTensorV2()\n",
        "        ])\n",
        "\n",
        "    self.transformations = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "  def transform(self, image, mask):\n",
        "    image = image.reshape(512,512,3)\n",
        "    mask = mask.reshape(512,512,3)\n",
        "    mask = mask.astype('uint8')\n",
        "    augmented=  self.albu_transformations(image=image,mask=mask)\n",
        "    image = augmented['image']\n",
        "    mask = augmented['mask']\n",
        "    mask= mask.reshape([3,512,512])\n",
        "    image, mask = image.type(torch.FloatTensor), mask.type(torch.FloatTensor)\n",
        "    return image, mask\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    image = np.load(self.image_paths[index])\n",
        "    mask = np.load(self.mask_paths[index])\n",
        "    image, mask = self.transform(image, mask)\n",
        "    return image, mask\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.image_paths)"
      ],
      "metadata": {
        "id": "DB1sDWWj6vRz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = pd.read_csv('/content/drive/MyDrive/data/Meta_Beta/meta.csv')\n",
        "alpha.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "rbJHqCHF-ueq",
        "outputId": "bb6e8586-2132-4a34-f88c-e4889b2541c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  index  patient_id  nodule_no  slice_no       original_image  \\\n",
              "0           0      0           1          0         0  0001_NI000_slice000   \n",
              "1           1      1           1          0         1  0001_NI000_slice001   \n",
              "2           2      2           1          0         2  0001_NI000_slice002   \n",
              "3           3      3           1          0         3  0001_NI000_slice003   \n",
              "4           4      4           1          0         4  0001_NI000_slice004   \n",
              "\n",
              "            mask_image  malignancy is_cancer  is_clean  is_nodule data_split  \n",
              "0  0001_MA000_slice000           5      True     False       True      Train  \n",
              "1  0001_MA000_slice001           5      True     False       True      Train  \n",
              "2  0001_MA000_slice002           5      True     False       True      Train  \n",
              "3  0001_MA000_slice003           5      True     False       True      Train  \n",
              "4  0001_MA000_slice004           5      True     False       True      Train  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c62d1803-9e4f-4dcc-bc4e-5a340a10e94c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>nodule_no</th>\n",
              "      <th>slice_no</th>\n",
              "      <th>original_image</th>\n",
              "      <th>mask_image</th>\n",
              "      <th>malignancy</th>\n",
              "      <th>is_cancer</th>\n",
              "      <th>is_clean</th>\n",
              "      <th>is_nodule</th>\n",
              "      <th>data_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0001_NI000_slice000</td>\n",
              "      <td>0001_MA000_slice000</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0001_NI000_slice001</td>\n",
              "      <td>0001_MA000_slice001</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0001_NI000_slice002</td>\n",
              "      <td>0001_MA000_slice002</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0001_NI000_slice003</td>\n",
              "      <td>0001_MA000_slice003</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0001_NI000_slice004</td>\n",
              "      <td>0001_MA000_slice004</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c62d1803-9e4f-4dcc-bc4e-5a340a10e94c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c62d1803-9e4f-4dcc-bc4e-5a340a10e94c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c62d1803-9e4f-4dcc-bc4e-5a340a10e94c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = '/content/drive/MyDrive/data/RGB_IMAGES/Image/'"
      ],
      "metadata": {
        "id": "pk7AwbYzD3SK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha['original_image'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "UGzJgM5qBAjq",
        "outputId": "7d295c2b-40c2-4495-ce36-133a711e4522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'0001_NI000_slice000'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha['original_image_prime']= alpha['original_image'].apply(lambda x:image_dir + x +'.npy')\n",
        "alpha.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "irUavWkp_02h",
        "outputId": "de70ce63-b263-43ea-93d3-78f2131edc36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  index  patient_id  nodule_no  slice_no       original_image  \\\n",
              "0           0      0           1          0         0  0001_NI000_slice000   \n",
              "1           1      1           1          0         1  0001_NI000_slice001   \n",
              "2           2      2           1          0         2  0001_NI000_slice002   \n",
              "3           3      3           1          0         3  0001_NI000_slice003   \n",
              "4           4      4           1          0         4  0001_NI000_slice004   \n",
              "\n",
              "            mask_image  malignancy is_cancer  is_clean  is_nodule data_split  \\\n",
              "0  0001_MA000_slice000           5      True     False       True      Train   \n",
              "1  0001_MA000_slice001           5      True     False       True      Train   \n",
              "2  0001_MA000_slice002           5      True     False       True      Train   \n",
              "3  0001_MA000_slice003           5      True     False       True      Train   \n",
              "4  0001_MA000_slice004           5      True     False       True      Train   \n",
              "\n",
              "                                original_image_prime  \n",
              "0  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...  \n",
              "1  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...  \n",
              "2  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...  \n",
              "3  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...  \n",
              "4  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-501eb738-9c8f-47d4-b954-b0e9cbbb9af8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>nodule_no</th>\n",
              "      <th>slice_no</th>\n",
              "      <th>original_image</th>\n",
              "      <th>mask_image</th>\n",
              "      <th>malignancy</th>\n",
              "      <th>is_cancer</th>\n",
              "      <th>is_clean</th>\n",
              "      <th>is_nodule</th>\n",
              "      <th>data_split</th>\n",
              "      <th>original_image_prime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0001_NI000_slice000</td>\n",
              "      <td>0001_MA000_slice000</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0001_NI000_slice001</td>\n",
              "      <td>0001_MA000_slice001</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0001_NI000_slice002</td>\n",
              "      <td>0001_MA000_slice002</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0001_NI000_slice003</td>\n",
              "      <td>0001_MA000_slice003</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0001_NI000_slice004</td>\n",
              "      <td>0001_MA000_slice004</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-501eb738-9c8f-47d4-b954-b0e9cbbb9af8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-501eb738-9c8f-47d4-b954-b0e9cbbb9af8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-501eb738-9c8f-47d4-b954-b0e9cbbb9af8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha['original_image_prime'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "n98HCfMZAddR",
        "outputId": "5bb95b42-9b32-492b-d911-5a8aa27036ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data/RGB_IMAGES/Image/0001_NI000_slice000.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask_dir = '/content/drive/MyDrive/data/RGB_IMAGES/Mask/'"
      ],
      "metadata": {
        "id": "2PFh6kAoEPpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha['mask_image_prime'] = alpha['original_image'].apply(lambda x:mask_dir+ x +'.npy')"
      ],
      "metadata": {
        "id": "gCi1Nk6eEChC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "G6bjwj2QFOOp",
        "outputId": "b7c74e7d-a93f-4034-aaea-e56fdcb01907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  index  patient_id  nodule_no  slice_no       original_image  \\\n",
              "0           0      0           1          0         0  0001_NI000_slice000   \n",
              "1           1      1           1          0         1  0001_NI000_slice001   \n",
              "2           2      2           1          0         2  0001_NI000_slice002   \n",
              "3           3      3           1          0         3  0001_NI000_slice003   \n",
              "4           4      4           1          0         4  0001_NI000_slice004   \n",
              "\n",
              "            mask_image  malignancy is_cancer  is_clean  is_nodule data_split  \\\n",
              "0  0001_MA000_slice000           5      True     False       True      Train   \n",
              "1  0001_MA000_slice001           5      True     False       True      Train   \n",
              "2  0001_MA000_slice002           5      True     False       True      Train   \n",
              "3  0001_MA000_slice003           5      True     False       True      Train   \n",
              "4  0001_MA000_slice004           5      True     False       True      Train   \n",
              "\n",
              "                                original_image_prime  \\\n",
              "0  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...   \n",
              "1  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...   \n",
              "2  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...   \n",
              "3  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...   \n",
              "4  /content/drive/MyDrive/data/RGB_IMAGES/Image/0...   \n",
              "\n",
              "                                    mask_image_prime  \n",
              "0  /content/drive/MyDrive/data/RGB_IMAGES/Mask/00...  \n",
              "1  /content/drive/MyDrive/data/RGB_IMAGES/Mask/00...  \n",
              "2  /content/drive/MyDrive/data/RGB_IMAGES/Mask/00...  \n",
              "3  /content/drive/MyDrive/data/RGB_IMAGES/Mask/00...  \n",
              "4  /content/drive/MyDrive/data/RGB_IMAGES/Mask/00...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-feece4a5-8c99-4256-9aa1-defffa59d18e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>index</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>nodule_no</th>\n",
              "      <th>slice_no</th>\n",
              "      <th>original_image</th>\n",
              "      <th>mask_image</th>\n",
              "      <th>malignancy</th>\n",
              "      <th>is_cancer</th>\n",
              "      <th>is_clean</th>\n",
              "      <th>is_nodule</th>\n",
              "      <th>data_split</th>\n",
              "      <th>original_image_prime</th>\n",
              "      <th>mask_image_prime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0001_NI000_slice000</td>\n",
              "      <td>0001_MA000_slice000</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Mask/00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0001_NI000_slice001</td>\n",
              "      <td>0001_MA000_slice001</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Mask/00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0001_NI000_slice002</td>\n",
              "      <td>0001_MA000_slice002</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Mask/00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0001_NI000_slice003</td>\n",
              "      <td>0001_MA000_slice003</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Mask/00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0001_NI000_slice004</td>\n",
              "      <td>0001_MA000_slice004</td>\n",
              "      <td>5</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>Train</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Image/0...</td>\n",
              "      <td>/content/drive/MyDrive/data/RGB_IMAGES/Mask/00...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-feece4a5-8c99-4256-9aa1-defffa59d18e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-feece4a5-8c99-4256-9aa1-defffa59d18e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-feece4a5-8c99-4256-9aa1-defffa59d18e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alpha['mask_image_prime'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jpdSSkiLFUpi",
        "outputId": "27ef190f-ba54-470c-cdeb-0e48464d70bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/data/RGB_IMAGES/Mask/0001_NI000_slice000.npy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Directory of Image, Mask folder generated from the preprocessing stage ###\n",
        "image_dir = '/content/drive/MyDrive/data/RGB_IMAGES/Image/'\n",
        "mask_dir = '/content/drive/MyDrive/data/RGB_IMAGES/Mask/'\n",
        "#mask_dir = '/content/drive/MyDrive/data/Nodule_data/mask/'\n",
        "meta = pd.read_csv('/content/drive/MyDrive/data/Meta_Beta/meta.csv')\n",
        "\n",
        "meta['original_image_prime']= meta['original_image'].apply(lambda x:image_dir+ x +'.npy')\n",
        "meta['mask_image_prime'] = meta['original_image'].apply(lambda x:mask_dir+ x +'.npy')\n",
        "\n",
        "train_meta = meta[meta['data_split']=='Train']\n",
        "val_meta = meta[meta['data_split']=='Validation']\n",
        "\n",
        "# Get all *npy images into list for Train\n",
        "train_image_paths = list(train_meta['original_image_prime'])\n",
        "train_mask_paths = list(train_meta['mask_image_prime'])\n",
        "\n",
        "# Get all *npy images into list for Validation\n",
        "val_image_paths = list(val_meta['original_image_prime'])\n",
        "val_mask_paths = list(val_meta['mask_image_prime'])\n",
        "\n",
        "print(\"*\"*50)\n",
        "print(\"The length of image: {}, mask folders: {} for train\".format(len(train_image_paths),len(train_mask_paths)))\n",
        "print(\"The length of image: {}, mask folders: {} for validation\".format(len(val_image_paths),len(val_mask_paths)))\n",
        "print(\"Ratio between Val/ Train is {:2f}\".format(len(val_image_paths)/len(train_image_paths)))\n",
        "print(\"*\"*50)\n",
        "\n",
        "print(train_image_paths[0])\n",
        "print(train_mask_paths[0])\n",
        "\n",
        "# Create Dataset\n",
        "train_dataset = MyLidcDataset(train_image_paths, train_mask_paths)\n",
        "val_dataset = MyLidcDataset(val_image_paths,val_mask_paths)\n",
        "\n",
        "batch_size = 4\n",
        "tr_dl = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    pin_memory=True,\n",
        "    drop_last=True,\n",
        "    num_workers=2)\n",
        "\n",
        "val_dl = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    drop_last=False,\n",
        "    num_workers=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "owGvNTQP9ii7",
        "outputId": "c4722ea2-ae16-4b0c-9d64-925d0c3b784c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************************************************\n",
            "The length of image: 8126, mask folders: 8126 for train\n",
            "The length of image: 2927, mask folders: 2927 for validation\n",
            "Ratio between Val/ Train is 0.360202\n",
            "**************************************************\n",
            "/content/drive/MyDrive/data/RGB_IMAGES/Image/0001_NI000_slice000.npy\n",
            "/content/drive/MyDrive/data/RGB_IMAGES/Mask/0001_NI000_slice000.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wiq8KNLyasIT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DiceLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Module to compute the Dice segmentation loss. Based on the following discussion:\n",
        "    https://discuss.pytorch.org/t/one-hot-encoding-with-autograd-dice-loss/9781\n",
        "    \"\"\"\n",
        "    def __init__(self, weights=None, ignore_index=None, eps=0.0001):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.weights = weights\n",
        "        self.ignore_index = ignore_index\n",
        "        self.eps = eps\n",
        "        \n",
        "    def forward(self, output, target):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            output: (N, C, H, W) tensor of probabilities for the predicted output\n",
        "            target: (N, H, W) tensor corresponding to the pixel-wise labels\n",
        "        Returns:\n",
        "            loss: the Dice loss averaged over channels\n",
        "        \"\"\" \n",
        "        encoded_target = output.detach() * 0\n",
        "        if self.ignore_index is not None:\n",
        "            mask = target == self.ignore_index\n",
        "            target = target.clone()\n",
        "            target[mask] = 0\n",
        "            encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "            mask = mask.unsqueeze(1).expand_as(encoded_target)\n",
        "            encoded_target[mask] = 0\n",
        "        else:\n",
        "            encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "        if self.weights is None:\n",
        "            self.weights = 1\n",
        "\n",
        "        intersection = output * encoded_target\n",
        "        numerator = 2 * intersection.sum(0).sum(1).sum(1)\n",
        "        denominator = output + encoded_target\n",
        "\n",
        "        if self.ignore_index is not None:\n",
        "            denominator[mask] = 0\n",
        "        denominator = denominator.sum(0).sum(1).sum(1) + self.eps\n",
        "        loss_per_channel = self.weights * (1 - (numerator / denominator))\n",
        "\n",
        "        return loss_per_channel.sum() / output.size(1)"
      ],
      "metadata": {
        "id": "OcYv-mF_6vO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_similarity(output, target, weights=None, ignore_index=None, eps=1e-8):\n",
        "    \"\"\"\n",
        "    Arguments:\n",
        "        output: (N, C, H, W) tensor of model output\n",
        "        target: (N, H, W) tensor corresponding to the pixel-wise labels\n",
        "    Returns:\n",
        "        loss: the Dice loss averaged over channels\n",
        "    \"\"\" \n",
        "    prediction = torch.softmax(output, dim=1)\n",
        "    encoded_prediction = output.detach() * 0\n",
        "    encoded_prediction.scatter_(1, prediction.unsqueeze(1), 1)\n",
        "    \n",
        "    encoded_target = output.detach() * 0\n",
        "    print(encoded_target)\n",
        "    if ignore_index is not None:\n",
        "        mask = target == ignore_index\n",
        "        target = target.clone()\n",
        "        target[mask] = 0\n",
        "        encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "        mask = mask.unsqueeze(1).expand_as(encoded_target)\n",
        "        encoded_target[mask] = 0\n",
        "    else:\n",
        "        encoded_target.scatter_(1, target.unsqueeze(1), 1)\n",
        "\n",
        "    if weights is None:\n",
        "        weights = 1\n",
        "\n",
        "    intersection = encoded_prediction * encoded_target\n",
        "    numerator = 2 * intersection.sum(0).sum(1).sum(1) + eps\n",
        "    denominator = intersection + encoded_target\n",
        "    if ignore_index is not None:\n",
        "        denominator[mask] = 0\n",
        "    denominator = denominator.sum(0).sum(1).sum(1) + eps\n",
        "    acc_per_channel = weights * ((numerator / denominator))\n",
        "\n",
        "    return acc_per_channel.sum() / output.size(1)"
      ],
      "metadata": {
        "id": "JthO9ghQ8E_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DynamicUNet(resnet34(), num_output_channels=32, input_size=(512, 512))"
      ],
      "metadata": {
        "id": "IjgYpN-B8PW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(model.parameters())[-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ebZJ6VGxMX-",
        "outputId": "af27eb28-cef4-4ccc-923c-31b78b18919c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def iou_score(output, target):\n",
        "    smooth = 1e-5\n",
        "\n",
        "    if torch.is_tensor(output):\n",
        "        output = torch.sigmoid(output).data.cpu().numpy()\n",
        "    if torch.is_tensor(target):\n",
        "        target = target.data.cpu().numpy()\n",
        "    output_ = output > 0.5\n",
        "    target_ = target > 0.5\n",
        "    intersection = (output_ & target_).sum()\n",
        "    union = (output_ | target_).sum()\n",
        "\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def dice_coef(output, target):\n",
        "    smooth = 1e-5\n",
        "\n",
        "    # we need to use sigmoid because the output of Unet is logit.\n",
        "    output = torch.sigmoid(output).view(-1).data.cpu().numpy()\n",
        "    target = target.view(-1).data.cpu().numpy()\n",
        "    intersection = (output * target).sum()\n",
        "    \n",
        "\n",
        "    return (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n",
        "\n",
        "def dice_coef2(output, target):\n",
        "    \"This metric is for validation purpose\"\n",
        "    smooth = 1e-5\n",
        "\n",
        "    output = output.view(-1)\n",
        "    output = (output>0.5).float().cpu().numpy()\n",
        "    target = target.view(-1).data.cpu().numpy()\n",
        "    intersection = (output * target).sum()\n",
        "    \n",
        "\n",
        "    return (2. * intersection + smooth) / (output.sum() + target.sum() + smooth)\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ['true', 1]:\n",
        "        return True\n",
        "    elif v.lower() in ['false', 0]:\n",
        "        return False\n",
        "\n",
        "def count_params(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "__all__ = ['BCEDiceLoss']\n",
        "\n",
        "class BCEDiceLoss(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, input, target):\n",
        "    bce = F.binary_cross_entropy_with_logits(input, target)\n",
        "    smooth = 1e-5\n",
        "    input = torch.sigmoid(input)\n",
        "    num = target.size(0)\n",
        "    input = input.view(num, -1)\n",
        "    target = target.view(num, -1)\n",
        "    intersection = (input * target)\n",
        "    dice = (2. * intersection.sum(1) + smooth) / (input.sum(1) + target.sum(1) + smooth)\n",
        "    dice = 1 - dice.sum() / num\n",
        "\n",
        "    return 0.5 * bce + dice\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "912ZWljbI6BK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Class for handling the dataset\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, resize_shape=(360, 480), is_train=True):\n",
        "        self.images, self.labels = [tpl[0] for tpl in data], \\\n",
        "                                   [tpl[1] for tpl in data]\n",
        "        self.resize_shape = resize_shape\n",
        "        self.is_train = is_train\n",
        "\n",
        "    def transform(self, index):\n",
        "        input, target = map(\n",
        "            Image.open, (self.images[index], self.labels[index]))\n",
        "        input, target = (\n",
        "            tf.resize(input, self.resize_shape),\n",
        "            tf.resize(target, self.resize_shape, interpolation=Image.NEAREST)\n",
        "        )\n",
        "        if self.is_train:\n",
        "            horizontal_draw = torch.rand(1).item()\n",
        "            vertical_draw = torch.rand(1).item()\n",
        "            if horizontal_draw > 0.5:\n",
        "                input, target = tf.hflip(input), tf.hflip(target)\n",
        "            if vertical_draw > 0.5:\n",
        "                input, target = tf.vflip(input), tf.vflip(target)\n",
        "        \n",
        "        input, target = map(tf.to_tensor, (input, target))\n",
        "        torch.clamp((255 * target), 0, 32, out=target)\n",
        "        return tf.normalize(input, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), target.long()\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.transform(index)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "metadata": {
        "id": "afUH1r6yGJmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DynamicUNet(resnet34(), num_output_channels=3, input_size=(512, 512))\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "decoder_parameters = [item for module in model.decoder for item in module.parameters()]\n",
        "optimizer = optim.AdamW(decoder_parameters)  # Only training the decoder for now\n",
        "\n",
        "criterion = DiceLoss()\n",
        "\n",
        "# Training specific parameters\n",
        "num_epochs = 10\n",
        "num_up_epochs, num_down_epochs = 3, 7\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
        "    optimizer, max_lr=1e-2,\n",
        "    total_steps=num_epochs * len(tr_dl),\n",
        ")\n"
      ],
      "metadata": {
        "id": "piOCeUV38igi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "losses = []\n",
        "accuracies = []\n",
        "\n",
        "tqdm_iterator = tqdm(range(num_epochs), position=0)\n",
        "for epoch in tqdm_iterator:\n",
        "    tr_loss, tr_correct_pixels, tr_total_pixels, tr_dice_similarity, total = 0., 0., 0., 0., 0.\n",
        "    tqdm_epoch_iterator = tqdm(tr_dl, position=1, leave=False)\n",
        "    for i, (x, y) in enumerate(tqdm_epoch_iterator):\n",
        "        optimizer.zero_grad()\n",
        "        print(y.shape)\n",
        "        if torch.cuda.is_available():\n",
        "          print(\"====== GPU is Here =========\")\n",
        "          x, y = x.cuda(), y.squeeze(dim=1).cuda()\n",
        "        output = model(x)\n",
        "        prediction = torch.softmax(output, dim=1)\n",
        "        print(prediction.shape)\n",
        "        print(y.shape)\n",
        "        tr_correct_pixels += ((prediction == y).sum())\n",
        "        tr_total_pixels += y.numel()\n",
        "        #tr_dice_similarity += dice_similarity(output, y.squeeze(1)) * len(y)\n",
        "        loss = criterion(output, y.squeeze(1))\n",
        "        tr_loss += loss.data.cpu() * len(y)\n",
        "        total += len(y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        if i % 1 == 0:\n",
        "            curr_loss = tr_loss / total\n",
        "            curr_acc = tr_correct_pixels / tr_total_pixels\n",
        "            #curr_dice = tr_dice_similarity / total\n",
        "            tqdm_epoch_iterator.set_postfix({\n",
        "                \"Loss\": curr_loss.item(), \"Accuracy\": curr_acc.item()\n",
        "            })\n",
        "    overall_loss = tr_loss.item() / total\n",
        "    overall_acc = tr_correct_pixels.item() / tr_total_pixels\n",
        "    losses.append(overall_loss)\n",
        "    accuracies.append(overall_acc)\n",
        "    tqdm_iterator.set_postfix({\"Loss\": overall_loss, \"Accuracy\": overall_acc})"
      ],
      "metadata": {
        "id": "VXB9cqj18idV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}